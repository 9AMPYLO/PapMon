---
http_interactions:
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/?arxiv_id=2211.05783
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Fri, 11 Nov 2022 17:48:34 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '1759'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=WktVSStdnrqoTw9sgEw94StOmW3EdbdP1PYb3wjoxsrup9hFskHiT6hYBDcwt2dmZXpXy9QBQzBlCRZReOWH4B9hD7i7okDcE%2FiqQecOkb5MX00KW3%2BoLPq8L6KA%2Bw%2B0PWWFUQ7GN0nydtYwSyIXTQ%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 7688dc07afb40504-HKG
    body:
      encoding: UTF-8
      string: '{"count":1,"next":null,"previous":null,"results":[{"id":"unifying-flow-stereo-and-depth-estimation","arxiv_id":"2211.05783","nips_id":null,"url_abs":"https://arxiv.org/abs/2211.05783v1","url_pdf":"https://arxiv.org/pdf/2211.05783v1.pdf","title":"Unifying
        Flow, Stereo and Depth Estimation","abstract":"We present a unified formulation
        and model for three motion and 3D perception tasks: optical flow, rectified
        stereo matching and unrectified stereo depth estimation from posed images.
        Unlike previous specialized architectures for each specific task, we formulate
        all three tasks as a unified dense correspondence matching problem, which
        can be solved with a single model by directly comparing feature similarities.
        Such a formulation calls for discriminative feature representations, which
        we achieve using a Transformer, in particular the cross-attention mechanism.
        We demonstrate that cross-attention enables integration of knowledge from
        another image via cross-view interactions, which greatly improves the quality
        of the extracted features. Our unified model naturally enables cross-task
        transfer since the model architecture and parameters are shared across tasks.
        We outperform RAFT with our unified model on the challenging Sintel dataset,
        and our final model that uses a few additional task-specific refinement steps
        outperforms or compares favorably to recent state-of-the-art methods on 10
        popular flow, stereo and depth datasets, while being simpler and more efficient
        in terms of model design and inference speed.","authors":["Andreas Geiger","DaCheng
        Tao","Fisher Yu","Hamid Rezatofighi","Jianfei Cai","Jing Zhang","Haofei Xu"],"published":"2022-11-10","conference":null,"conference_url_abs":null,"conference_url_pdf":null,"proceeding":null}]}'
  recorded_at: Fri, 11 Nov 2022 17:48:34 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/unifying-flow-stereo-and-depth-estimation/repositories/
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Fri, 11 Nov 2022 17:48:35 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '259'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=9YXYaZNEgfOSKFtWQM0qNF2e0LYHWrxB%2FVOPKnW8KNpT9krR42yln1craVh4Y50zPmiKy8LE3aUc%2Bs3af%2B1hGHFXz%2Fq42WJWRJhyERT9CnRviRjxIAMYZ813eLs5IiHQ0VCX%2FPsU6PF7UI0UTN072w%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 7688dc0aab161092-HKG
    body:
      encoding: UTF-8
      string: '{"count":1,"next":null,"previous":null,"results":[{"url":"https://github.com/autonomousvision/unimatch","owner":"autonomousvision","name":"unimatch","description":"Unifying
        Flow, Stereo and Depth Estimation","stars":52,"framework":"none","is_official":true}]}'
  recorded_at: Fri, 11 Nov 2022 17:48:35 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/unifying-flow-stereo-and-depth-estimation/datasets/
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Fri, 11 Nov 2022 17:48:36 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '1160'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=WdiZUctI%2FS60xkaOb8XiaXNZ2IYfoj8wsFc4ywo6tzaHBYt7fUrc2%2BTrl8DZSoph50Ua%2FMN6%2Fu1hnHx8ju9cwZ8T7%2BmNLrqm4nGUfnib4EZ0fBv7WknwQ4zYMe1aCv9HZxYbJD67iX3eeXjDBCO9dg%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 7688dc10ac1f0987-HKG
    body:
      encoding: UTF-8
      string: '{"count":10,"next":null,"previous":null,"results":[{"id":"middlebury","name":"Middlebury","full_name":"Middlebury
        Stereo","url":"https://vision.middlebury.edu/stereo/data/"},{"id":"flyingthings3d","name":"FlyingThings3D","full_name":"","url":"https://lmb.informatik.uni-freiburg.de/resources/datasets/SceneFlowDatasets.en.html"},{"id":"kitti","name":"KITTI","full_name":"","url":"http://www.cvlibs.net/datasets/kitti/"},{"id":"tartanair","name":"TartanAir","full_name":"","url":"http://theairlab.org/tartanair-dataset/"},{"id":"sun3d","name":"SUN3D","full_name":"SUN3D","url":"http://sun3d.cs.princeton.edu/"},{"id":"scannet","name":"ScanNet","full_name":"","url":"http://www.scan-net.org/"},{"id":"flyingchairs","name":"FlyingChairs","full_name":"","url":"https://lmb.informatik.uni-freiburg.de/resources/datasets/FlyingChairs.en.html"},{"id":"virtual-kitti-2","name":"Virtual
        KITTI 2","full_name":"","url":"https://europe.naverlabs.com/Research/Computer-Vision/Proxy-Virtual-Worlds"},{"id":"eth3d","name":"ETH3D","full_name":"","url":"https://www.eth3d.net/"},{"id":"argoverse","name":"Argoverse","full_name":"","url":"https://www.argoverse.org/data.html"}]}'
  recorded_at: Fri, 11 Nov 2022 17:48:36 GMT
- request:
    method: get
    uri: http://export.arxiv.org/api/query?search_query=cat:cs.CV%20OR%20cat:cs.AI%20OR%20cat:cs.LG%20OR%20cat:cs.CL%20OR%20cat:cs.NE%20OR%20cat:stat.ML%20&sortBy=lastUpdatedDate&sortOrder=descending
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - export.arxiv.org
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Fri, 11 Nov 2022 17:48:36 GMT
      Server:
      - Apache
      Access-Control-Allow-Origin:
      - "*"
      Vary:
      - Accept-Encoding,User-Agent
      Connection:
      - close
      Transfer-Encoding:
      - chunked
      Content-Type:
      - application/atom+xml; charset=UTF-8
    body:
      encoding: UTF-8
      string: |
        <?xml version="1.0" encoding="UTF-8"?>
        <feed xmlns="http://www.w3.org/2005/Atom">
          <link href="http://arxiv.org/api/query?search_query%3Dcat%3Acs.CV%20OR%20cat%3Acs.AI%20OR%20cat%3Acs.LG%20OR%20cat%3Acs.CL%20OR%20cat%3Acs.NE%20OR%20cat%3Astat.ML%20%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
          <title type="html">ArXiv Query: search_query=cat:cs.CV OR cat:cs.AI OR cat:cs.LG OR cat:cs.CL OR cat:cs.NE OR cat:stat.ML &amp;id_list=&amp;start=0&amp;max_results=10</title>
          <id>http://arxiv.org/api/Ng7l2usAsA+y01hV0NniA5J/7uE</id>
          <updated>2022-11-11T00:00:00-05:00</updated>
          <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">247561</opensearch:totalResults>
          <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
          <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
          <entry>
            <id>http://arxiv.org/abs/2211.05783v1</id>
            <updated>2022-11-10T18:59:54Z</updated>
            <published>2022-11-10T18:59:54Z</published>
            <title>Unifying Flow, Stereo and Depth Estimation</title>
            <summary>  We present a unified formulation and model for three motion and 3D perception
        tasks: optical flow, rectified stereo matching and unrectified stereo depth
        estimation from posed images. Unlike previous specialized architectures for
        each specific task, we formulate all three tasks as a unified dense
        correspondence matching problem, which can be solved with a single model by
        directly comparing feature similarities. Such a formulation calls for
        discriminative feature representations, which we achieve using a Transformer,
        in particular the cross-attention mechanism. We demonstrate that
        cross-attention enables integration of knowledge from another image via
        cross-view interactions, which greatly improves the quality of the extracted
        features. Our unified model naturally enables cross-task transfer since the
        model architecture and parameters are shared across tasks. We outperform RAFT
        with our unified model on the challenging Sintel dataset, and our final model
        that uses a few additional task-specific refinement steps outperforms or
        compares favorably to recent state-of-the-art methods on 10 popular flow,
        stereo and depth datasets, while being simpler and more efficient in terms of
        model design and inference speed.
        </summary>
            <author>
              <name>Haofei Xu</name>
            </author>
            <author>
              <name>Jing Zhang</name>
            </author>
            <author>
              <name>Jianfei Cai</name>
            </author>
            <author>
              <name>Hamid Rezatofighi</name>
            </author>
            <author>
              <name>Fisher Yu</name>
            </author>
            <author>
              <name>Dacheng Tao</name>
            </author>
            <author>
              <name>Andreas Geiger</name>
            </author>
            <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Project Page: https://haofeixu.github.io/unimatch, Code:
          https://github.com/autonomousvision/unimatch</arxiv:comment>
            <link href="http://arxiv.org/abs/2211.05783v1" rel="alternate" type="text/html"/>
            <link title="pdf" href="http://arxiv.org/pdf/2211.05783v1" rel="related" type="application/pdf"/>
            <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
            <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
          </entry>
          <entry>
            <id>http://arxiv.org/abs/2211.05781v1</id>
            <updated>2022-11-10T18:59:43Z</updated>
            <published>2022-11-10T18:59:43Z</published>
            <title>Demystify Transformers &amp; Convolutions in Modern Image Deep Networks</title>
            <summary>  Recent success of vision transformers has inspired a series of vision
        backbones with novel feature transformation paradigms, which report steady
        performance gain. Although the novel feature transformation designs are often
        claimed as the source of gain, some backbones may benefit from advanced
        engineering techniques, which makes it hard to identify the real gain from the
        key feature transformation operators. In this paper, we aim to identify real
        gain of popular convolution and attention operators and make an in-depth study
        of them. We observe that the main difference among these feature transformation
        modules, e.g., attention or convolution, lies in the way of spatial feature
        aggregation, or the so-called "spatial token mixer" (STM). Hence, we first
        elaborate a unified architecture to eliminate the unfair impact of different
        engineering techniques, and then fit STMs into this architecture for
        comparison. Based on various experiments on upstream/downstream tasks and the
        analysis of inductive bias, we find that the engineering techniques boost the
        performance significantly, but the performance gap still exists among different
        STMs. The detailed analysis also reveals some interesting findings of different
        STMs, such as effective receptive fields and invariance tests. The code and
        trained models will be publicly available at
        https://github.com/OpenGVLab/STM-Evaluation
        </summary>
            <author>
              <name>Jifeng Dai</name>
            </author>
            <author>
              <name>Min Shi</name>
            </author>
            <author>
              <name>Weiyun Wang</name>
            </author>
            <author>
              <name>Sitong Wu</name>
            </author>
            <author>
              <name>Linjie Xing</name>
            </author>
            <author>
              <name>Wenhai Wang</name>
            </author>
            <author>
              <name>Xizhou Zhu</name>
            </author>
            <author>
              <name>Lewei Lu</name>
            </author>
            <author>
              <name>Jie Zhou</name>
            </author>
            <author>
              <name>Xiaogang Wang</name>
            </author>
            <author>
              <name>Yu Qiao</name>
            </author>
            <author>
              <name>Xiaowei Hu</name>
            </author>
            <link href="http://arxiv.org/abs/2211.05781v1" rel="alternate" type="text/html"/>
            <link title="pdf" href="http://arxiv.org/pdf/2211.05781v1" rel="related" type="application/pdf"/>
            <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
            <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
          </entry>
          <entry>
            <id>http://arxiv.org/abs/2210.14891v4</id>
            <updated>2022-11-10T18:59:30Z</updated>
            <published>2022-10-26T17:45:01Z</published>
            <title>Broken Neural Scaling Laws</title>
            <summary>  We present a smoothly broken power law functional form that accurately models
        and extrapolates the scaling behaviors of deep neural networks (i.e. how the
        evaluation metric of interest varies as the amount of compute used for
        training, number of model parameters, training dataset size, or upstream
        performance varies) for each task within a large and diverse set of upstream
        and downstream tasks, in zero-shot, prompted, and fine-tuned settings. This set
        includes large-scale vision and unsupervised language tasks, diffusion
        generative modeling of images, arithmetic, and reinforcement learning. When
        compared to other functional forms for neural scaling behavior, this functional
        form yields extrapolations of scaling behavior that are considerably more
        accurate on this set. Moreover, this functional form accurately models and
        extrapolates scaling behavior that other functional forms are incapable of
        expressing such as the non-monotonic transitions present in the scaling
        behavior of phenomena such as double descent and the delayed, sharp inflection
        points present in the scaling behavior of tasks such as arithmetic. Lastly, we
        use this functional form to glean insights about the limit of the
        predictability of scaling behavior. Code is available at
        https://github.com/ethancaballero/broken_neural_scaling_laws
        </summary>
            <author>
              <name>Ethan Caballero</name>
            </author>
            <author>
              <name>Kshitij Gupta</name>
            </author>
            <author>
              <name>Irina Rish</name>
            </author>
            <author>
              <name>David Krueger</name>
            </author>
            <link href="http://arxiv.org/abs/2210.14891v4" rel="alternate" type="text/html"/>
            <link title="pdf" href="http://arxiv.org/pdf/2210.14891v4" rel="related" type="application/pdf"/>
            <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
            <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
            <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
          </entry>
          <entry>
            <id>http://arxiv.org/abs/2211.05778v1</id>
            <updated>2022-11-10T18:59:04Z</updated>
            <published>2022-11-10T18:59:04Z</published>
            <title>InternImage: Exploring Large-Scale Vision Foundation Models with
          Deformable Convolutions</title>
            <summary>  Compared to the great progress of large-scale vision transformers (ViTs) in
        recent years, large-scale models based on convolutional neural networks (CNNs)
        are still in an early state. This work presents a new large-scale CNN-based
        foundation model, termed InternImage, which can obtain the gain from increasing
        parameters and training data like ViTs. Different from the recent CNNs that
        focus on large dense kernels, InternImage takes deformable convolution as the
        core operator, so that our model not only has the large effective receptive
        field required for downstream tasks such as detection and segmentation, but
        also has the adaptive spatial aggregation conditioned by input and task
        information. As a result, the proposed InternImage reduces the strict inductive
        bias of traditional CNNs and makes it possible to learn stronger and more
        robust patterns with large-scale parameters from massive data like ViTs. The
        effectiveness of our model is proven on challenging benchmarks including
        ImageNet, COCO, and ADE20K. It is worth mentioning that InternImage-H achieved
        the new record 65.4 mAP on COCO test-dev. The code will be released at
        https://github.com/OpenGVLab/InternImage.
        </summary>
            <author>
              <name>Wenhai Wang</name>
            </author>
            <author>
              <name>Jifeng Dai</name>
            </author>
            <author>
              <name>Zhe Chen</name>
            </author>
            <author>
              <name>Zhenhang Huang</name>
            </author>
            <author>
              <name>Zhiqi Li</name>
            </author>
            <author>
              <name>Xizhou Zhu</name>
            </author>
            <author>
              <name>Xiaowei Hu</name>
            </author>
            <author>
              <name>Tong Lu</name>
            </author>
            <author>
              <name>Lewei Lu</name>
            </author>
            <author>
              <name>Hongsheng Li</name>
            </author>
            <author>
              <name>Xiaogang Wang</name>
            </author>
            <author>
              <name>Yu Qiao</name>
            </author>
            <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">technical report</arxiv:comment>
            <link href="http://arxiv.org/abs/2211.05778v1" rel="alternate" type="text/html"/>
            <link title="pdf" href="http://arxiv.org/pdf/2211.05778v1" rel="related" type="application/pdf"/>
            <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
            <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
          </entry>
          <entry>
            <id>http://arxiv.org/abs/2211.05777v1</id>
            <updated>2022-11-10T18:58:30Z</updated>
            <published>2022-11-10T18:58:30Z</published>
            <title>Hybrid quantum neural network for drug response prediction</title>
            <summary>  Cancer is one of the leading causes of death worldwide. It is caused by a
        variety of genetic mutations, which makes every instance of the disease unique.
        Since chemotherapy can have extremely severe side effects, each patient
        requires a personalized treatment plan. Finding the dosages that maximize the
        beneficial effects of the drugs and minimize their adverse side effects is
        vital. Deep neural networks automate and improve drug selection. However, they
        require a lot of data to be trained on. Therefore, there is a need for
        machine-learning approaches that require less data. Hybrid quantum neural
        networks were shown to provide a potential advantage in problems where training
        data availability is limited. We propose a novel hybrid quantum neural network
        for drug response prediction, based on a combination of convolutional, graph
        convolutional, and deep quantum neural layers of 8 qubits with 363 layers. We
        test our model on the reduced Genomics of Drug Sensitivity in Cancer dataset
        and show that the hybrid quantum model outperforms its classical analog by 15%
        in predicting IC50 drug effectiveness values. The proposed hybrid quantum
        machine learning model is a step towards deep quantum data-efficient algorithms
        with thousands of quantum gates for solving problems in personalized medicine,
        where data collection is a challenge.
        </summary>
            <author>
              <name>Asel Sagingalieva</name>
            </author>
            <author>
              <name>Mohammad Kordzanganeh</name>
            </author>
            <author>
              <name>Nurbolat Kenbayev</name>
            </author>
            <author>
              <name>Daria Kosichkina</name>
            </author>
            <author>
              <name>Tatiana Tomashuk</name>
            </author>
            <author>
              <name>Alexey Melnikov</name>
            </author>
            <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 3 figures</arxiv:comment>
            <link href="http://arxiv.org/abs/2211.05777v1" rel="alternate" type="text/html"/>
            <link title="pdf" href="http://arxiv.org/pdf/2211.05777v1" rel="related" type="application/pdf"/>
            <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
            <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
            <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
          </entry>
          <entry>
            <id>http://arxiv.org/abs/2211.05776v1</id>
            <updated>2022-11-10T18:58:22Z</updated>
            <published>2022-11-10T18:58:22Z</published>
            <title>Fine-Grained Entity Segmentation</title>
            <summary>  In dense image segmentation tasks (e.g., semantic, panoptic), existing
        methods can hardly generalize well to unseen image domains, predefined classes,
        and image resolution &amp; quality variations. Motivated by these observations, we
        construct a large-scale entity segmentation dataset to explore fine-grained
        entity segmentation, with a strong focus on open-world and high-quality dense
        segmentation. The dataset contains images spanning diverse image domains and
        resolutions, along with high-quality mask annotations for training and testing.
        Given the high-quality and -resolution nature of the dataset, we propose
        CropFormer for high-quality segmentation, which can improve mask prediction
        using high-res image crops that provide more fine-grained image details than
        the full image. CropFormer is the first query-based Transformer architecture
        that can effectively ensemble mask predictions from multiple image crops, by
        learning queries that can associate the same entities across the full image and
        its crop. With CropFormer, we achieve a significant AP gain of $1.9$ on the
        challenging fine-grained entity segmentation task. The dataset and code will be
        released at http://luqi.info/entityv2.github.io/.
        </summary>
            <author>
              <name>Lu Qi</name>
            </author>
            <author>
              <name>Jason Kuen</name>
            </author>
            <author>
              <name>Weidong Guo</name>
            </author>
            <author>
              <name>Tiancheng Shen</name>
            </author>
            <author>
              <name>Jiuxiang Gu</name>
            </author>
            <author>
              <name>Wenbo Li</name>
            </author>
            <author>
              <name>Jiaya Jia</name>
            </author>
            <author>
              <name>Zhe Lin</name>
            </author>
            <author>
              <name>Ming-Hsuan Yang</name>
            </author>
            <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The project webiste: http://luqi.info/entityv2.github.io/</arxiv:comment>
            <link href="http://arxiv.org/abs/2211.05776v1" rel="alternate" type="text/html"/>
            <link title="pdf" href="http://arxiv.org/pdf/2211.05776v1" rel="related" type="application/pdf"/>
            <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
            <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
          </entry>
          <entry>
            <id>http://arxiv.org/abs/2211.05773v1</id>
            <updated>2022-11-10T18:58:00Z</updated>
            <published>2022-11-10T18:58:00Z</published>
            <title>Scaling Neural Face Synthesis to High FPS and Low Latency by Neural
          Caching</title>
            <summary>  Recent neural rendering approaches greatly improve image quality, reaching
        near photorealism. However, the underlying neural networks have high runtime,
        precluding telepresence and virtual reality applications that require high
        resolution at low latency. The sequential dependency of layers in deep networks
        makes their optimization difficult. We break this dependency by caching
        information from the previous frame to speed up the processing of the current
        one with an implicit warp. The warping with a shallow network reduces latency
        and the caching operations can further be parallelized to improve the frame
        rate. In contrast to existing temporal neural networks, ours is tailored for
        the task of rendering novel views of faces by conditioning on the change of the
        underlying surface mesh. We test the approach on view-dependent rendering of 3D
        portrait avatars, as needed for telepresence, on established benchmark
        sequences. Warping reduces latency by 70$\%$ (from 49.4ms to 14.9ms on
        commodity GPUs) and scales frame rates accordingly over multiple GPUs while
        reducing image quality by only 1$\%$, making it suitable as part of end-to-end
        view-dependent 3D teleconferencing applications. Our project page can be found
        at: https://yu-frank.github.io/lowlatency/.
        </summary>
            <author>
              <name>Frank Yu</name>
            </author>
            <author>
              <name>Sid Fels</name>
            </author>
            <author>
              <name>Helge Rhodin</name>
            </author>
            <link href="http://arxiv.org/abs/2211.05773v1" rel="alternate" type="text/html"/>
            <link title="pdf" href="http://arxiv.org/pdf/2211.05773v1" rel="related" type="application/pdf"/>
            <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
            <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
          </entry>
          <entry>
            <id>http://arxiv.org/abs/2209.15001v2</id>
            <updated>2022-11-10T18:57:10Z</updated>
            <published>2022-09-29T17:57:08Z</published>
            <title>Dilated Neighborhood Attention Transformer</title>
            <summary>  Transformers are quickly becoming one of the most heavily applied deep
        learning architectures across modalities, domains, and tasks. In vision, on top
        of ongoing efforts into plain transformers, hierarchical transformers have also
        gained significant attention, thanks to their performance and easy integration
        into existing frameworks. These models typically employ localized attention
        mechanisms, such as the sliding-window Neighborhood Attention (NA) or Swin
        Transformer's Shifted Window Self Attention. While effective at reducing self
        attention's quadratic complexity, local attention weakens two of the most
        desirable properties of self attention: long range inter-dependency modeling,
        and global receptive field. In this paper, we introduce Dilated Neighborhood
        Attention (DiNA), a natural, flexible and efficient extension to NA that can
        capture more global context and expand receptive fields exponentially at no
        additional cost. NA's local attention and DiNA's sparse global attention
        complement each other, and therefore we introduce Dilated Neighborhood
        Attention Transformer (DiNAT), a new hierarchical vision transformer built upon
        both. DiNAT variants enjoy significant improvements over strong baselines such
        as NAT, Swin, and ConvNeXt. Our large model is faster and ahead of its Swin
        counterpart by 1.5% box AP in COCO object detection, 1.3% mask AP in COCO
        instance segmentation, and 1.1% mIoU in ADE20K semantic segmentation. Paired
        with new frameworks, our large variant is the new state of the art panoptic
        segmentation model on COCO (58.2 PQ) and ADE20K (48.5 PQ), and instance
        segmentation model on Cityscapes (44.5 AP) and ADE20K (35.4 AP) (no extra
        data). It also matches the state of the art specialized semantic segmentation
        models on ADE20K (58.2 mIoU), and ranks second on Cityscapes (84.5 mIoU) (no
        extra data). We open-source our project.
        </summary>
            <author>
              <name>Ali Hassani</name>
            </author>
            <author>
              <name>Humphrey Shi</name>
            </author>
            <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">We open-source our project at:
          https://github.com/SHI-Labs/Neighborhood-Attention-Transformer</arxiv:comment>
            <link href="http://arxiv.org/abs/2209.15001v2" rel="alternate" type="text/html"/>
            <link title="pdf" href="http://arxiv.org/pdf/2209.15001v2" rel="related" type="application/pdf"/>
            <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
            <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
            <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
            <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
          </entry>
          <entry>
            <id>http://arxiv.org/abs/2204.07143v4</id>
            <updated>2022-11-10T18:55:49Z</updated>
            <published>2022-04-14T17:55:15Z</published>
            <title>Neighborhood Attention Transformer</title>
            <summary>  We present Neighborhood Attention (NA), the first efficient and scalable
        sliding-window attention mechanism for vision. NA is a pixel-wise operation,
        localizing self attention (SA) to the nearest neighboring pixels, and therefore
        enjoys a linear time and space complexity compared to the quadratic complexity
        of SA. The sliding-window pattern allows NA's receptive field to grow without
        needing extra pixel shifts, and preserves translational equivariance, unlike
        Swin Transformer's Window Self Attention (WSA). We develop NATTEN (Neighborhood
        Attention Extension), a Python package with efficient C++ and CUDA kernels,
        which allows NA to run up to 40% faster than Swin's WSA while using up to 25%
        less memory. We further present Neighborhood Attention Transformer (NAT), a new
        hierarchical transformer design based on NA that boosts image classification
        and downstream vision performance. Experimental results on NAT are competitive;
        NAT-Tiny reaches 83.2% top-1 accuracy on ImageNet, 51.4% mAP on MS-COCO and
        48.4% mIoU on ADE20K, which is 1.9% ImageNet accuracy, 1.0% COCO mAP, and 2.6%
        ADE20K mIoU improvement over a Swin model with similar size. To support more
        research based on sliding-window attention, we open source our project and
        release our checkpoints at:
        https://github.com/SHI-Labs/Neighborhood-Attention-Transformer .
        </summary>
            <author>
              <name>Ali Hassani</name>
            </author>
            <author>
              <name>Steven Walton</name>
            </author>
            <author>
              <name>Jiachen Li</name>
            </author>
            <author>
              <name>Shen Li</name>
            </author>
            <author>
              <name>Humphrey Shi</name>
            </author>
            <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Revision with details on our new Neighborhood Attention Extension
          (NATTEN), along with analysis on translational equivariance in
          attention-based models. NATTEN is open-sourced at:
          https://github.com/SHI-Labs/NATTEN/</arxiv:comment>
            <link href="http://arxiv.org/abs/2204.07143v4" rel="alternate" type="text/html"/>
            <link title="pdf" href="http://arxiv.org/pdf/2204.07143v4" rel="related" type="application/pdf"/>
            <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
            <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
            <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
            <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
          </entry>
          <entry>
            <id>http://arxiv.org/abs/2211.05770v1</id>
            <updated>2022-11-10T18:55:48Z</updated>
            <published>2022-11-10T18:55:48Z</published>
            <title>StyleNAT: Giving Each Head a New Perspective</title>
            <summary>  Image generation has been a long sought-after but challenging task, and
        performing the generation task in an efficient manner is similarly difficult.
        Often researchers attempt to create a "one size fits all" generator, where
        there are few differences in the parameter space for drastically different
        datasets. Herein, we present a new transformer-based framework, dubbed
        StyleNAT, targeting high-quality image generation with superior efficiency and
        flexibility. At the core of our model, is a carefully designed framework that
        partitions attention heads to capture local and global information, which is
        achieved through using Neighborhood Attention (NA). With different heads able
        to pay attention to varying receptive fields, the model is able to better
        combine this information, and adapt, in a highly flexible manner, to the data
        at hand. StyleNAT attains a new SOTA FID score on FFHQ-256 with 2.046, beating
        prior arts with convolutional models such as StyleGAN-XL and transformers such
        as HIT and StyleSwin, and a new transformer SOTA on FFHQ-1024 with an FID score
        of 4.174. These results show a 6.4% improvement on FFHQ-256 scores when
        compared to StyleGAN-XL with a 28% reduction in the number of parameters and
        56% improvement in sampling throughput. Code and models will be open-sourced at
        https://github.com/SHI-Labs/StyleNAT .
        </summary>
            <author>
              <name>Steven Walton</name>
            </author>
            <author>
              <name>Ali Hassani</name>
            </author>
            <author>
              <name>Xingqian Xu</name>
            </author>
            <author>
              <name>Zhangyang Wang</name>
            </author>
            <author>
              <name>Humphrey Shi</name>
            </author>
            <link href="http://arxiv.org/abs/2211.05770v1" rel="alternate" type="text/html"/>
            <link title="pdf" href="http://arxiv.org/pdf/2211.05770v1" rel="related" type="application/pdf"/>
            <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
            <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
            <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
            <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
          </entry>
        </feed>
  recorded_at: Fri, 11 Nov 2022 17:48:37 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/?arxiv_id=2211.05781
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:38:58 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '2000'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=6yRuI6WqK7k0VFJyk%2FPNXh2woyxIpQUrELQvLAa%2BnvbnQk3GdKC3rH5J2ZabJ9UD2c0SHugEqpOML7k5HfZw1KqFe%2BD3fNX0oehH8f0dnXzdqLeTmVNHZi%2FQ%2BcOdmzkelUnijg%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 769898ef9be234ff-NRT
    body:
      encoding: UTF-8
      string: '{"count":1,"next":null,"previous":null,"results":[{"id":"demystify-transformers-convolutions-in-modern","arxiv_id":"2211.05781","nips_id":null,"url_abs":"https://arxiv.org/abs/2211.05781v1","url_pdf":"https://arxiv.org/pdf/2211.05781v1.pdf","title":"Demystify
        Transformers & Convolutions in Modern Image Deep Networks","abstract":"Recent
        success of vision transformers has inspired a series of vision backbones with
        novel feature transformation paradigms, which report steady performance gain.
        Although the novel feature transformation designs are often claimed as the
        source of gain, some backbones may benefit from advanced engineering techniques,
        which makes it hard to identify the real gain from the key feature transformation
        operators. In this paper, we aim to identify real gain of popular convolution
        and attention operators and make an in-depth study of them. We observe that
        the main difference among these feature transformation modules, e.g., attention
        or convolution, lies in the way of spatial feature aggregation, or the so-called
        \"spatial token mixer\" (STM). Hence, we first elaborate a unified architecture
        to eliminate the unfair impact of different engineering techniques, and then
        fit STMs into this architecture for comparison. Based on various experiments
        on upstream/downstream tasks and the analysis of inductive bias, we find that
        the engineering techniques boost the performance significantly, but the performance
        gap still exists among different STMs. The detailed analysis also reveals
        some interesting findings of different STMs, such as effective receptive fields
        and invariance tests. The code and trained models will be publicly available
        at https://github.com/OpenGVLab/STM-Evaluation","authors":["Xiaowei Hu","Yu
        Qiao","Xiaogang Wang","Jie zhou","Lewei Lu","Xizhou Zhu","Wenhai Wang","Linjie
        Xing","Sitong Wu","Weiyun Wang","Min Shi","Jifeng Dai"],"published":"2022-11-10","conference":null,"conference_url_abs":null,"conference_url_pdf":null,"proceeding":null}]}'
  recorded_at: Sun, 13 Nov 2022 15:38:58 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/demystify-transformers-convolutions-in-modern/repositories/
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:38:59 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '215'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=8U9pfFVNEvJwbcK7nDDaY6yhNNv8SqFpOhupk7ddgxRivKYSWjMkIZJYw3zFbZM4uxjfRPl59eBLhG%2F12O61FknWNYeFEGVtA4D4r3Rd9Uc8pg3MP1U4dj7g1HrU7U6ZgeeFDQ%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 769898f739f5b011-NRT
    body:
      encoding: UTF-8
      string: '{"count":1,"next":null,"previous":null,"results":[{"url":"https://github.com/opengvlab/stm-evaluation","owner":"opengvlab","name":"stm-evaluation","description":"","stars":22,"framework":"none","is_official":true}]}'
  recorded_at: Sun, 13 Nov 2022 15:39:00 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/demystify-transformers-convolutions-in-modern/datasets/
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:01 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '253'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=3nRnVIVUrqyFCUDXjkFOhCWL1iEw8nWQoYChQ1mkYZrwPAnQgsbl6EqFVMOt3uVUDbRBZo3qy5r6mbXs4Xpq8%2FJBYza%2FjZBLQ33Rp8JylIZszxrvavfyu9FJF3pSz4MdFOdAqA%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 769898ff9a38c9ef-NRT
    body:
      encoding: UTF-8
      string: '{"count":2,"next":null,"previous":null,"results":[{"id":"imagenet","name":"ImageNet","full_name":"","url":"https://image-net.org/index.php"},{"id":"coco","name":"COCO","full_name":"Microsoft
        Common Objects in Context","url":"https://cocodataset.org/"}]}'
  recorded_at: Sun, 13 Nov 2022 15:39:01 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/?arxiv_id=2210.14891
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:02 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '1783'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=LbgP%2B2rGrIzvFh3CbveveU0y1b1OsTSsz7%2Bw%2BE3Nxacp5RkKfXqu9VIftwObW1fQ9jV4B8H8SQkpmpHRtszXATJW4%2FrDY61IdzKMhjkd9puQkDl7ci22QlBOQd6fModVZ4Uivw%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 76989909fe96e370-NRT
    body:
      encoding: UTF-8
      string: '{"count":1,"next":null,"previous":null,"results":[{"id":"broken-neural-scaling-laws","arxiv_id":"2210.14891","nips_id":null,"url_abs":"https://arxiv.org/abs/2210.14891v4","url_pdf":"https://arxiv.org/pdf/2210.14891v4.pdf","title":"Broken
        Neural Scaling Laws","abstract":"We present a smoothly broken power law functional
        form that accurately models and extrapolates the scaling behaviors of deep
        neural networks (i.e. how the evaluation metric of interest varies as the
        amount of compute used for training, number of model parameters, training
        dataset size, or upstream performance varies) for each task within a large
        and diverse set of upstream and downstream tasks, in zero-shot, prompted,
        and fine-tuned settings. This set includes large-scale vision and unsupervised
        language tasks, diffusion generative modeling of images, arithmetic, and reinforcement
        learning. When compared to other functional forms for neural scaling behavior,
        this functional form yields extrapolations of scaling behavior that are considerably
        more accurate on this set. Moreover, this functional form accurately models
        and extrapolates scaling behavior that other functional forms are incapable
        of expressing such as the non-monotonic transitions present in the scaling
        behavior of phenomena such as double descent and the delayed, sharp inflection
        points present in the scaling behavior of tasks such as arithmetic. Lastly,
        we use this functional form to glean insights about the limit of the predictability
        of scaling behavior. Code is available at https://github.com/ethancaballero/broken_neural_scaling_laws","authors":["David
        Krueger","Irina Rish","Kshitij Gupta","Ethan Caballero"],"published":"2022-10-26","conference":null,"conference_url_abs":null,"conference_url_pdf":null,"proceeding":null}]}'
  recorded_at: Sun, 13 Nov 2022 15:39:02 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/broken-neural-scaling-laws/repositories/
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:03 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '302'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=Gl%2FPzbWzUQnH%2FJ%2FwdJggqpzgVM9lmQKQ861VSMD8zkiMnDnW6HvrxxqCxePShFQq17masUZ2hr8cNYuMFvCXslPlPV%2F0XJfxTChIgbh%2FoGWR3Jf3G9YS0htt9k3Tj4vh5Tp%2BuQ%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 7698990da8e1dfd5-NRT
    body:
      encoding: UTF-8
      string: '{"count":1,"next":null,"previous":null,"results":[{"url":"https://github.com/ethancaballero/broken_neural_scaling_laws","owner":"ethancaballero","name":"broken_neural_scaling_laws","description":"Code
        Release for \"Broken Neural Scaling Laws\" paper","stars":14,"framework":"none","is_official":true}]}'
  recorded_at: Sun, 13 Nov 2022 15:39:03 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/broken-neural-scaling-laws/datasets/
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:04 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '501'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=2mg1HitSNFsgKxws16h6a%2FamUk7pKW5KHQefHu7Um8QEi3GloLOsRniDE8hdjLi9FGCF4iUxnatyWhs2t3DGuC085qwp6njovosiYbgIrn438w6iMwdmwG0bChxKATxtGux6WQ%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 769899117c53f641-NRT
    body:
      encoding: UTF-8
      string: '{"count":4,"next":null,"previous":null,"results":[{"id":"caltech-101","name":"Caltech-101","full_name":"","url":"http://www.vision.caltech.edu/Image_Datasets/Caltech101/"},{"id":"imagenet","name":"ImageNet","full_name":"","url":"https://image-net.org/index.php"},{"id":"cifar-100","name":"CIFAR-100","full_name":"","url":"https://www.cs.toronto.edu/~kriz/cifar.html"},{"id":"big-bench","name":"BIG-bench","full_name":"Beyond
        the Imitation Game Benchmark","url":"https://github.com/google/BIG-bench"}]}'
  recorded_at: Sun, 13 Nov 2022 15:39:04 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/?arxiv_id=2211.05778
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:06 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '1814'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=%2BXg4E0A%2FF%2B8u6eTDdNG64vu3aokCnG%2FobtHVbgPcPfcZH09do3%2BTqtM32DeKNdOxSfcTpRO2uFS2x6WlRUMzr10UHSxCoUoBlhlFjCXrTjnV8JsMyQRuVu2wVVSW%2FFF2UN3xkw%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 76989919eba780c9-NRT
    body:
      encoding: UTF-8
      string: '{"count":1,"next":null,"previous":null,"results":[{"id":"internimage-exploring-large-scale-vision","arxiv_id":"2211.05778","nips_id":null,"url_abs":"https://arxiv.org/abs/2211.05778v1","url_pdf":"https://arxiv.org/pdf/2211.05778v1.pdf","title":"InternImage:
        Exploring Large-Scale Vision Foundation Models with Deformable Convolutions","abstract":"Compared
        to the great progress of large-scale vision transformers (ViTs) in recent
        years, large-scale models based on convolutional neural networks (CNNs) are
        still in an early state. This work presents a new large-scale CNN-based foundation
        model, termed InternImage, which can obtain the gain from increasing parameters
        and training data like ViTs. Different from the recent CNNs that focus on
        large dense kernels, InternImage takes deformable convolution as the core
        operator, so that our model not only has the large effective receptive field
        required for downstream tasks such as detection and segmentation, but also
        has the adaptive spatial aggregation conditioned by input and task information.
        As a result, the proposed InternImage reduces the strict inductive bias of
        traditional CNNs and makes it possible to learn stronger and more robust patterns
        with large-scale parameters from massive data like ViTs. The effectiveness
        of our model is proven on challenging benchmarks including ImageNet, COCO,
        and ADE20K. It is worth mentioning that InternImage-H achieved the new record
        65.4 mAP on COCO test-dev. The code will be released at https://github.com/OpenGVLab/InternImage.","authors":["Yu
        Qiao","Xiaogang Wang","Hongsheng Li","Lewei Lu","Tong Lu","Xiaowei Hu","Xizhou
        Zhu","Zhiqi Li","Zhenhang Huang","Zhe Chen","Jifeng Dai","Wenhai Wang"],"published":"2022-11-10","conference":null,"conference_url_abs":null,"conference_url_pdf":null,"proceeding":null}]}'
  recorded_at: Sun, 13 Nov 2022 15:39:06 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/internimage-exploring-large-scale-vision/repositories/
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:06 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '209'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=wTIQIvbX0Yza4eVKQururCb8GcQWMKUuRVUrUhIr7VrGWnZJOv2e8Y%2FGxBbMiBf73V0zyNY6fbVJjdHJre9fGAybkYcKJX01CNQVIim%2FCevGLdbAj%2Beo9Il8qVHQK2dN2qH%2B9A%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 769899248e7b80d5-NRT
    body:
      encoding: UTF-8
      string: '{"count":1,"next":null,"previous":null,"results":[{"url":"https://github.com/opengvlab/internimage","owner":"opengvlab","name":"internimage","description":"","stars":63,"framework":"none","is_official":true}]}'
  recorded_at: Sun, 13 Nov 2022 15:39:06 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/internimage-exploring-large-scale-vision/datasets/
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:07 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '361'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=r1yxybkeWS%2F4lPrVPiXYjMXe75NbmxYqfv04FdGSMZy%2BCWp7IFyrS1jOst03M61JRqeYs%2Bd%2BwG%2F3FCDB5rXP53k%2BqUqLkC9BNqV0k0Fre2PgkAR%2B6zaGQRwuDR1mabEbcsNWDA%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 76989928c8ba80ff-NRT
    body:
      encoding: UTF-8
      string: '{"count":3,"next":null,"previous":null,"results":[{"id":"imagenet","name":"ImageNet","full_name":"","url":"https://image-net.org/index.php"},{"id":"coco","name":"COCO","full_name":"Microsoft
        Common Objects in Context","url":"https://cocodataset.org/"},{"id":"ade20k","name":"ADE20K","full_name":"","url":"https://groups.csail.mit.edu/vision/datasets/ADE20K/"}]}'
  recorded_at: Sun, 13 Nov 2022 15:39:07 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/?arxiv_id=2211.05777
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:08 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '1907'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=wBFu3qS169F%2Bq2570yDStRQATYuz3midUMEJ2YVrgM4gWW6KImHL%2F6FUrIhidhYc2XVRzS4MDI%2B9e08ar9eTPOj4rLq%2FSJeBVPZtitwIaEQjrP8NG44ZPzZTzClsnMO2hLrzhw%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 7698992d28d88075-NRT
    body:
      encoding: UTF-8
      string: '{"count":1,"next":null,"previous":null,"results":[{"id":"hybrid-quantum-neural-network-for-drug","arxiv_id":"2211.05777","nips_id":null,"url_abs":"https://arxiv.org/abs/2211.05777v1","url_pdf":"https://arxiv.org/pdf/2211.05777v1.pdf","title":"Hybrid
        quantum neural network for drug response prediction","abstract":"Cancer is
        one of the leading causes of death worldwide. It is caused by a variety of
        genetic mutations, which makes every instance of the disease unique. Since
        chemotherapy can have extremely severe side effects, each patient requires
        a personalized treatment plan. Finding the dosages that maximize the beneficial
        effects of the drugs and minimize their adverse side effects is vital. Deep
        neural networks automate and improve drug selection. However, they require
        a lot of data to be trained on. Therefore, there is a need for machine-learning
        approaches that require less data. Hybrid quantum neural networks were shown
        to provide a potential advantage in problems where training data availability
        is limited. We propose a novel hybrid quantum neural network for drug response
        prediction, based on a combination of convolutional, graph convolutional,
        and deep quantum neural layers of 8 qubits with 363 layers. We test our model
        on the reduced Genomics of Drug Sensitivity in Cancer dataset and show that
        the hybrid quantum model outperforms its classical analog by 15% in predicting
        IC50 drug effectiveness values. The proposed hybrid quantum machine learning
        model is a step towards deep quantum data-efficient algorithms with thousands
        of quantum gates for solving problems in personalized medicine, where data
        collection is a challenge.","authors":["Alexey Melnikov","Tatiana Tomashuk","Daria
        Kosichkina","Nurbolat Kenbayev","Mohammad Kordzanganeh","Asel Sagingalieva"],"published":"2022-11-10","conference":null,"conference_url_abs":null,"conference_url_pdf":null,"proceeding":null}]}'
  recorded_at: Sun, 13 Nov 2022 15:39:08 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/hybrid-quantum-neural-network-for-drug/repositories/
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:09 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '52'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=6HZedHoPPopjKW%2BJ3KHLJc9Tjppy5aE8plVpqOpPZKloKPdVu81zKYxKltByZaDV50rhHm%2B5wd%2BfHpgZmotqWG7TNsqnPwlb1B16%2B0EVQb3lVhf%2B8i4UVbvmmFl0FE4Ok0oHkA%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 76989933a8fee045-NRT
    body:
      encoding: UTF-8
      string: '{"count":0,"next":null,"previous":null,"results":[]}'
  recorded_at: Sun, 13 Nov 2022 15:39:09 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/hybrid-quantum-neural-network-for-drug/datasets/
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:09 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '52'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=aLX5jen1VOFsEHs0te3LARWYGmh8lnxngu%2BSzTbWiDvbkBSgxeGwSFHWilomotKYizVGGVx2P%2B716uo094GQTR3w7OrMYIMR1XDVM7%2FPBS8wejcMnsGciZzPunk5%2Bw5aeHXUAA%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 7698993789e1e3bf-NRT
    body:
      encoding: UTF-8
      string: '{"count":0,"next":null,"previous":null,"results":[]}'
  recorded_at: Sun, 13 Nov 2022 15:39:09 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/?arxiv_id=2211.05776
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:11 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '1735'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=3i%2FH%2BpT458BUodpgWBQFDl6tQHn1Asag94HVZoqe%2B7%2BgVDo2w3gTQUXHyAwNxIgLvCZPZZaz5zVUWCQ4py7ojCqlZFXJRGD4LygaUIu034jXrxmgGctTj31AgRmmQ93gRLSQrg%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 7698993b9aa58a6c-NRT
    body:
      encoding: UTF-8
      string: '{"count":1,"next":null,"previous":null,"results":[{"id":"fine-grained-entity-segmentation","arxiv_id":"2211.05776","nips_id":null,"url_abs":"https://arxiv.org/abs/2211.05776v1","url_pdf":"https://arxiv.org/pdf/2211.05776v1.pdf","title":"Fine-Grained
        Entity Segmentation","abstract":"In dense image segmentation tasks (e.g.,
        semantic, panoptic), existing methods can hardly generalize well to unseen
        image domains, predefined classes, and image resolution & quality variations.
        Motivated by these observations, we construct a large-scale entity segmentation
        dataset to explore fine-grained entity segmentation, with a strong focus on
        open-world and high-quality dense segmentation. The dataset contains images
        spanning diverse image domains and resolutions, along with high-quality mask
        annotations for training and testing. Given the high-quality and -resolution
        nature of the dataset, we propose CropFormer for high-quality segmentation,
        which can improve mask prediction using high-res image crops that provide
        more fine-grained image details than the full image. CropFormer is the first
        query-based Transformer architecture that can effectively ensemble mask predictions
        from multiple image crops, by learning queries that can associate the same
        entities across the full image and its crop. With CropFormer, we achieve a
        significant AP gain of $1.9$ on the challenging fine-grained entity segmentation
        task. The dataset and code will be released at http://luqi.info/entityv2.github.io/.","authors":["Ming-Hsuan
        Yang","Zhe Lin","Jiaya Jia","Wenbo Li","Jiuxiang Gu","Tiancheng Shen","Weidong
        Guo","Jason Kuen","Lu Qi"],"published":"2022-11-10","conference":null,"conference_url_abs":null,"conference_url_pdf":null,"proceeding":null}]}'
  recorded_at: Sun, 13 Nov 2022 15:39:11 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/fine-grained-entity-segmentation/repositories/
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:12 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '52'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=9KlSVjyhW2jBZP6PExhSIOWHg5bxc4SSxgOLyvHV9Xty2fEvOGe7D4Dp1RDPHEU4wfcmcz2EwxcfkdrTqvEAO5zoyrPurkzlBNenDswdNVlbWDSyW8eSRd7rGqOVVNih6OI3lg%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 769899441f24aff4-NRT
    body:
      encoding: UTF-8
      string: '{"count":0,"next":null,"previous":null,"results":[]}'
  recorded_at: Sun, 13 Nov 2022 15:39:12 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/fine-grained-entity-segmentation/datasets/
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:13 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '882'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=xIdZENV2ctIuIFF%2Bb6wH9zcBLmHvr0HbpEQPhXcchDPRXVfxQmUELOFtQ9qfuURvPfTE9GLdTVs8%2B8rBy7ffVxarMyKURg4JZQnwGMwyVbhoaVhpGu2O7Kpkaw4R5Pmz5tiwVg%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 7698994b8d471d7b-NRT
    body:
      encoding: UTF-8
      string: '{"count":8,"next":null,"previous":null,"results":[{"id":"ade20k","name":"ADE20K","full_name":"","url":"https://groups.csail.mit.edu/vision/datasets/ADE20K/"},{"id":"cityscapes","name":"Cityscapes","full_name":"","url":"https://www.cityscapes-dataset.com/dataset-overview/"},{"id":"synscapes","name":"Synscapes","full_name":"","url":"https://7dlabs.com/synscapes-overview"},{"id":"coco","name":"COCO","full_name":"Microsoft
        Common Objects in Context","url":"https://cocodataset.org/"},{"id":"laion-400m","name":"LAION-400M","full_name":"","url":"https://laion.ai/laion-400-open-dataset/"},{"id":"lvis","name":"LVIS","full_name":"","url":"https://www.lvisdataset.org/dataset"},{"id":"gta5","name":"GTA5","full_name":"Grand
        Theft Auto 5","url":"https://arxiv.org/pdf/1608.02192v1.pdf"},{"id":"entityseg","name":"EntitySeg","full_name":"","url":"http://luqi.info/entityv2.github.io/"}]}'
  recorded_at: Sun, 13 Nov 2022 15:39:13 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/?arxiv_id=2211.05773
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:13 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '1775'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=qUBptPnYF8%2Fys%2B4tOhJoBsdeM2%2FrQa7FgX07m8AqvTpjUNpSWU9vWaVBmAnoBxbhNic8i1Nci5C9F%2BsiYrEIcznJ10YWhqgWp90Hx8knukpflDdQ648XbIAKECIOPcAoGwT3TA%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 76989950ba79808f-NRT
    body:
      encoding: UTF-8
      string: '{"count":1,"next":null,"previous":null,"results":[{"id":"scaling-neural-face-synthesis-to-high-fps-and","arxiv_id":"2211.05773","nips_id":null,"url_abs":"https://arxiv.org/abs/2211.05773v1","url_pdf":"https://arxiv.org/pdf/2211.05773v1.pdf","title":"Scaling
        Neural Face Synthesis to High FPS and Low Latency by Neural Caching","abstract":"Recent
        neural rendering approaches greatly improve image quality, reaching near photorealism.
        However, the underlying neural networks have high runtime, precluding telepresence
        and virtual reality applications that require high resolution at low latency.
        The sequential dependency of layers in deep networks makes their optimization
        difficult. We break this dependency by caching information from the previous
        frame to speed up the processing of the current one with an implicit warp.
        The warping with a shallow network reduces latency and the caching operations
        can further be parallelized to improve the frame rate. In contrast to existing
        temporal neural networks, ours is tailored for the task of rendering novel
        views of faces by conditioning on the change of the underlying surface mesh.
        We test the approach on view-dependent rendering of 3D portrait avatars, as
        needed for telepresence, on established benchmark sequences. Warping reduces
        latency by 70$\\%$ (from 49.4ms to 14.9ms on commodity GPUs) and scales frame
        rates accordingly over multiple GPUs while reducing image quality by only
        1$\\%$, making it suitable as part of end-to-end view-dependent 3D teleconferencing
        applications. Our project page can be found at: https://yu-frank.github.io/lowlatency/.","authors":["Helge
        Rhodin","Sid Fels","Frank Yu"],"published":"2022-11-10","conference":null,"conference_url_abs":null,"conference_url_pdf":null,"proceeding":null}]}'
  recorded_at: Sun, 13 Nov 2022 15:39:13 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/scaling-neural-face-synthesis-to-high-fps-and/repositories/
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:15 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '52'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=UqKvQmr3G%2FOx8ZF7GdvL2stvLnEQK%2B2%2FCMbkaWEGRf3lm615XuYqXQHbshxPxT4Er0EEqXUG8E%2B8FIoE9DN5UeLhSnNNEdEId7gOtGP9IoZXvBfj4tcRupJojZxwbRwgPiEzcw%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 769899545b22f691-NRT
    body:
      encoding: UTF-8
      string: '{"count":0,"next":null,"previous":null,"results":[]}'
  recorded_at: Sun, 13 Nov 2022 15:39:15 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/scaling-neural-face-synthesis-to-high-fps-and/datasets/
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:16 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '52'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=uUWsOPhtaYrRS0itd1aTvjwP6FDR1iamCK78lwm6nh6VtQ7DP8NhOwHqxqUrDSx5QQWkQ2vuNJXrfwKOa87LDvdlPuCd5W%2ByF1h3OEYwxff8cPygVUAsqrC2F24VyTYgmg81yQ%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 7698995c59b6af3d-NRT
    body:
      encoding: UTF-8
      string: '{"count":0,"next":null,"previous":null,"results":[]}'
  recorded_at: Sun, 13 Nov 2022 15:39:16 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/?arxiv_id=2209.15001
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:16 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '2329'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=WK7paLPvQnODOh6JoaH2zBQAC5BmSyXy55z6cDZb88iN9gpljRUJimncR4KGKdCJD0rrGoP5HZW6fPGUPgXAbWj6PiXalT79HjaY%2FBe21YPcxdpYjEfBgZbm7phC7mR%2BuM7fBA%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 769899636bb7af7f-NRT
    body:
      encoding: UTF-8
      string: '{"count":1,"next":null,"previous":null,"results":[{"id":"dilated-neighborhood-attention-transformer","arxiv_id":"2209.15001","nips_id":null,"url_abs":"https://arxiv.org/abs/2209.15001v2","url_pdf":"https://arxiv.org/pdf/2209.15001v2.pdf","title":"Dilated
        Neighborhood Attention Transformer","abstract":"Transformers are quickly becoming
        one of the most heavily applied deep learning architectures across modalities,
        domains, and tasks. In vision, on top of ongoing efforts into plain transformers,
        hierarchical transformers have also gained significant attention, thanks to
        their performance and easy integration into existing frameworks. These models
        typically employ localized attention mechanisms, such as the sliding-window
        Neighborhood Attention (NA) or Swin Transformer''s Shifted Window Self Attention.
        While effective at reducing self attention''s quadratic complexity, local
        attention weakens two of the most desirable properties of self attention:
        long range inter-dependency modeling, and global receptive field. In this
        paper, we introduce Dilated Neighborhood Attention (DiNA), a natural, flexible
        and efficient extension to NA that can capture more global context and expand
        receptive fields exponentially at no additional cost. NA''s local attention
        and DiNA''s sparse global attention complement each other, and therefore we
        introduce Dilated Neighborhood Attention Transformer (DiNAT), a new hierarchical
        vision transformer built upon both. DiNAT variants enjoy significant improvements
        over strong baselines such as NAT, Swin, and ConvNeXt. Our large model is
        faster and ahead of its Swin counterpart by 1.5% box AP in COCO object detection,
        1.3% mask AP in COCO instance segmentation, and 1.1% mIoU in ADE20K semantic
        segmentation. Paired with new frameworks, our large variant is the new state
        of the art panoptic segmentation model on COCO (58.2 PQ) and ADE20K (48.5
        PQ), and instance segmentation model on Cityscapes (44.5 AP) and ADE20K (35.4
        AP) (no extra data). It also matches the state of the art specialized semantic
        segmentation models on ADE20K (58.2 mIoU), and ranks second on Cityscapes
        (84.5 mIoU) (no extra data). We open-source our project.","authors":["Humphrey
        Shi","Ali Hassani"],"published":"2022-09-29","conference":null,"conference_url_abs":null,"conference_url_pdf":null,"proceeding":null}]}'
  recorded_at: Sun, 13 Nov 2022 15:39:16 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/dilated-neighborhood-attention-transformer/repositories/
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:17 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '538'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=Jaf1oQUA6JGqdVnFmHPn8TrsD5cATkcUhq18HeEsxfod3Emfb3ItG05jJW4FsX6KBg1q6dvRMD9CR18P9FfidCFr9yfqAIhTe9VgNfIHoBw68N0P7R5t5l6%2FiyaLz%2FoRtGzAUA%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 769899679a28e001-NRT
    body:
      encoding: UTF-8
      string: '{"count":2,"next":null,"previous":null,"results":[{"url":"https://github.com/SHI-Labs/Neighborhood-Attention-Transformer","owner":"SHI-Labs","name":"Neighborhood-Attention-Transformer","description":"[Preprint]
        Neighborhood Attention Transformer, 2022","stars":686,"framework":"pytorch","is_official":true},{"url":"https://github.com/shi-labs/natten","owner":"shi-labs","name":"natten","description":"Neighborhood
        Attention Extension. Bringing attention to a neighborhood near you!","stars":36,"framework":"pytorch","is_official":false}]}'
  recorded_at: Sun, 13 Nov 2022 15:39:17 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/dilated-neighborhood-attention-transformer/datasets/
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:17 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '477'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=NIr6F%2F747NTJrm1Rx8kKxojpamwn7pfNxj1j8wh5BWyh2sFSwfXJJja4SsAFp6pF7zU2OhMTnsTqo0aNK%2FdiWma55lLssbeJ8sKeOM9LS2p94KKrWx7dqGnsdo%2B6aCa8RZWGEQ%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 7698996b2de9e09c-NRT
    body:
      encoding: UTF-8
      string: '{"count":4,"next":null,"previous":null,"results":[{"id":"ade20k","name":"ADE20K","full_name":"","url":"https://groups.csail.mit.edu/vision/datasets/ADE20K/"},{"id":"cityscapes","name":"Cityscapes","full_name":"","url":"https://www.cityscapes-dataset.com/dataset-overview/"},{"id":"imagenet","name":"ImageNet","full_name":"","url":"https://image-net.org/index.php"},{"id":"coco","name":"COCO","full_name":"Microsoft
        Common Objects in Context","url":"https://cocodataset.org/"}]}'
  recorded_at: Sun, 13 Nov 2022 15:39:17 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/?arxiv_id=2204.07143
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:18 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '1818'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=1gRxL4mtT4zChs06CT6hD%2FgvNiNnD9ANEyiAv76G5onWXmzyPHSZBCVJByRH%2FB5foOgihz9MgqT3qYnm2n%2FiA7UHQuzFy82nGx34X9v7uTiJa4a2S0JbhrcrA6zxOHbNEfgGjw%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 7698996ed9dde05a-NRT
    body:
      encoding: UTF-8
      string: '{"count":1,"next":null,"previous":null,"results":[{"id":"neighborhood-attention-transformer","arxiv_id":"2204.07143","nips_id":null,"url_abs":"https://arxiv.org/abs/2204.07143v4","url_pdf":"https://arxiv.org/pdf/2204.07143v4.pdf","title":"Neighborhood
        Attention Transformer","abstract":"We present Neighborhood Attention (NA),
        the first efficient and scalable sliding-window attention mechanism for vision.
        NA is a pixel-wise operation, localizing self attention (SA) to the nearest
        neighboring pixels, and therefore enjoys a linear time and space complexity
        compared to the quadratic complexity of SA. The sliding-window pattern allows
        NA''s receptive field to grow without needing extra pixel shifts, and preserves
        translational equivariance, unlike Swin Transformer''s Window Self Attention
        (WSA). We develop NATTEN (Neighborhood Attention Extension), a Python package
        with efficient C++ and CUDA kernels, which allows NA to run up to 40% faster
        than Swin''s WSA while using up to 25% less memory. We further present Neighborhood
        Attention Transformer (NAT), a new hierarchical transformer design based on
        NA that boosts image classification and downstream vision performance. Experimental
        results on NAT are competitive; NAT-Tiny reaches 83.2% top-1 accuracy on ImageNet,
        51.4% mAP on MS-COCO and 48.4% mIoU on ADE20K, which is 1.9% ImageNet accuracy,
        1.0% COCO mAP, and 2.6% ADE20K mIoU improvement over a Swin model with similar
        size. To support more research based on sliding-window attention, we open
        source our project and release our checkpoints at: https://github.com/SHI-Labs/Neighborhood-Attention-Transformer
        .","authors":["Humphrey Shi","Shen Li","Jiachen Li","Steven Walton","Ali Hassani"],"published":"2022-04-14","conference":null,"conference_url_abs":null,"conference_url_pdf":null,"proceeding":null}]}'
  recorded_at: Sun, 13 Nov 2022 15:39:18 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/neighborhood-attention-transformer/repositories/
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:19 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '1418'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=y%2BAleYjfaLtgXrR9jydtSI1aFpiqPRcJfIFELFix12cgmy99ocguKCh7YjaAG%2Fs1ZA9veIRgJDCVpPNnaz0bk%2BNkmsjLesNxBd2ID4APsvZQe0nzu8k76IjYQQWs8bXFQF08uw%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 769899737ad0f6c1-NRT
    body:
      encoding: UTF-8
      string: '{"count":4,"next":null,"previous":null,"results":[{"url":"https://github.com/shi-labs/natten","owner":"shi-labs","name":"natten","description":"Neighborhood
        Attention Extension. Bringing attention to a neighborhood near you!","stars":36,"framework":"pytorch","is_official":true},{"url":"https://github.com/SHI-Labs/Neighborhood-Attention-Transformer","owner":"SHI-Labs","name":"Neighborhood-Attention-Transformer","description":"[Preprint]
        Neighborhood Attention Transformer, 2022","stars":686,"framework":"pytorch","is_official":true},{"url":"https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/nat","owner":"leondgarse","name":"keras_cv_attention_models","description":"Keras/Tensorflow
        attention models including beit,botnet,CMT,CoaT,CoAtNet,convnext,cotnet,davit,efficientdet,edgenext,efficientformer,efficientnet,fbnet,gcvit,gmlp,halonet,hornet,lcnet,levit,maxvit,mlp-mixer,mobilevit,nat,nfnets,regnet,resmlp,resnest,resnext,resnetd,swin,tinynet,uniformer,volo,wavemlp,yolor,yolox","stars":292,"framework":"tf","is_official":false},{"url":"https://github.com/qwopqwop200/Neighborhood-Attention-Transformer","owner":"qwopqwop200","name":"Neighborhood-Attention-Transformer","description":"NAT
        implementation(Neighborhood Attention Transformer) This is an unofficial implementation.
        https://arxiv.org/pdf/2204.07143.pdf","stars":3,"framework":"pytorch","is_official":false}]}'
  recorded_at: Sun, 13 Nov 2022 15:39:19 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/neighborhood-attention-transformer/datasets/
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:20 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '250'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=fgwN%2FrrIf85kn9%2FqwnAXQo5d%2BR509Y8cWpXzgKPE1x8BznNZreHZoWHAl6NVZ4Ur35V8buC9lEhXQkNN9vkD2di1QbER6j31CIj6ZnM9uvRmclna%2FTG0EoGenEnnKfhXk1FIUQ%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 769899787c62e014-NRT
    body:
      encoding: UTF-8
      string: '{"count":2,"next":null,"previous":null,"results":[{"id":"ade20k","name":"ADE20K","full_name":"","url":"https://groups.csail.mit.edu/vision/datasets/ADE20K/"},{"id":"imagenet","name":"ImageNet","full_name":"","url":"https://image-net.org/index.php"}]}'
  recorded_at: Sun, 13 Nov 2022 15:39:20 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/?arxiv_id=2211.05770
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:20 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '1853'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=Fo9HuFkm37D2E3wxiVKpOK9gi80cDLTj8V%2By6Y%2BwVjWMbivRdad6kUKQEIGseGZuR1RrR%2Bd8%2BPXYhwHYAq00OxBWlpGmJ4UsW7xI%2F0DPSll4fgyPtP9FH9Jj3gN3b9uaGEImGw%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 7698997c48248075-NRT
    body:
      encoding: UTF-8
      string: '{"count":1,"next":null,"previous":null,"results":[{"id":"stylenat-giving-each-head-a-new-perspective","arxiv_id":"2211.05770","nips_id":null,"url_abs":"https://arxiv.org/abs/2211.05770v1","url_pdf":"https://arxiv.org/pdf/2211.05770v1.pdf","title":"StyleNAT:
        Giving Each Head a New Perspective","abstract":"Image generation has been
        a long sought-after but challenging task, and performing the generation task
        in an efficient manner is similarly difficult. Often researchers attempt to
        create a \"one size fits all\" generator, where there are few differences
        in the parameter space for drastically different datasets. Herein, we present
        a new transformer-based framework, dubbed StyleNAT, targeting high-quality
        image generation with superior efficiency and flexibility. At the core of
        our model, is a carefully designed framework that partitions attention heads
        to capture local and global information, which is achieved through using Neighborhood
        Attention (NA). With different heads able to pay attention to varying receptive
        fields, the model is able to better combine this information, and adapt, in
        a highly flexible manner, to the data at hand. StyleNAT attains a new SOTA
        FID score on FFHQ-256 with 2.046, beating prior arts with convolutional models
        such as StyleGAN-XL and transformers such as HIT and StyleSwin, and a new
        transformer SOTA on FFHQ-1024 with an FID score of 4.174. These results show
        a 6.4% improvement on FFHQ-256 scores when compared to StyleGAN-XL with a
        28% reduction in the number of parameters and 56% improvement in sampling
        throughput. Code and models will be open-sourced at https://github.com/SHI-Labs/StyleNAT
        .","authors":["Humphrey Shi","Zhangyang Wang","Xingqian Xu","Ali Hassani","Steven
        Walton"],"published":"2022-11-10","conference":null,"conference_url_abs":null,"conference_url_pdf":null,"proceeding":null}]}'
  recorded_at: Sun, 13 Nov 2022 15:39:20 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/stylenat-giving-each-head-a-new-perspective/repositories/
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:21 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '261'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=hSg8QBw4dFbMESs8su0Ca0BQmWD0CILcDzs9GlQfMedjQwIryJDvURzeSVISmBognqcZ0lkRRwKQ1O8FQsTljJuQ3vSQIiSad9LAavn6iynaykT7uHyq6Oeux5%2Bc8RShbm3psA%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 7698997f586ee07e-NRT
    body:
      encoding: UTF-8
      string: '{"count":1,"next":null,"previous":null,"results":[{"url":"https://github.com/SHI-Labs/StyleNAT","owner":"SHI-Labs","name":"StyleNAT","description":"[Preprint]
        StyleNAT: Giving Each Head a New Perspective 2022","stars":29,"framework":"none","is_official":true}]}'
  recorded_at: Sun, 13 Nov 2022 15:39:21 GMT
- request:
    method: get
    uri: https://paperswithcode.com/api/v1/papers/stylenat-giving-each-head-a-new-perspective/datasets/
    body:
      encoding: UTF-8
      string: ''
    headers:
      Accept:
      - application/json
      Connection:
      - close
      Host:
      - paperswithcode.com
      User-Agent:
      - http.rb/5.1.0
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sun, 13 Nov 2022 15:39:21 GMT
      Content-Type:
      - application/json
      Content-Length:
      - '273'
      Connection:
      - close
      Vary:
      - Accept, Cookie
      Allow:
      - GET, HEAD, OPTIONS
      Permissions-Policy:
      - accelerometer=(), ambient-light-sensor=(), autoplay=(), camera=(), display-capture=(),
        document-domain=(), encrypted-media=(), fullscreen=(), geolocation=(), gyroscope=(),
        interest-cohort=(), magnetometer=(), microphone=(), midi=(), payment=(), usb=()
      Content-Security-Policy:
      - 'img-src * data: blob: ''unsafe-inline''; style-src ''self'' ''unsafe-inline''
        https://fonts.googleapis.com https://unpkg.com https://cdnjs.cloudflare.com
        https://maxcdn.bootstrapcdn.com https://code.jquery.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        http://localhost:3000 http://localhost:4000; script-src ''self'' blob: ''unsafe-inline''
        ''unsafe-eval'' https://www.googletagmanager.com https://www.google-analytics.com
        https://unpkg.com https://ajax.googleapis.com https://browser.sentry-cdn.com
        https://cdnjs.cloudflare.com https://maxcdn.bootstrapcdn.com https://code.jquery.com
        https://cdn.jsdelivr.net https://production-assets.paperswithcode.com https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000;
        manifest-src https://production-assets.paperswithcode.com; frame-src https://www.youtube.com/;
        default-src ''self''; font-src * data: blob: ''unsafe-inline''; connect-src
        ''self'' https://unpkg.com https://www.google-analytics.com https://sentry.io
        https://o241170.ingest.sentry.io https://production-assets.paperswithcode.com
        https://production-assets.paperswithcode.com http://localhost:3000 http://localhost:4000
        ws://localhost:3000 ws://localhost:4000; media-src * data: blob: ''unsafe-inline'';
        report-uri https://o241170.ingest.sentry.io/api/5629308/security/?sentry_key=6284059d22664211881c89b4c409c619'
      Referrer-Policy:
      - no-referrer-when-downgrade
      X-Frame-Options:
      - DENY
      Strict-Transport-Security:
      - max-age=10368000; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - 1; mode=block
      Cf-Cache-Status:
      - DYNAMIC
      Report-To:
      - '{"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v3?s=O8%2BSb%2FnE8QbKvC4qkfaHLEHakobKDrogxB%2Fz2xEcQPldYkKOyThcBILHhXHrwrYyyHhHE%2FMqcRf8vZrpyuO1Ddj6iJJK%2BxBNr6hNr9Ff7x6KPWQtE2G%2FVRvgYJgY6mLi2D%2FchA%3D%3D"}],"group":"cf-nel","max_age":604800}'
      Nel:
      - '{"success_fraction":0,"report_to":"cf-nel","max_age":604800}'
      Server:
      - cloudflare
      Cf-Ray:
      - 7698998349c73438-NRT
    body:
      encoding: UTF-8
      string: '{"count":2,"next":null,"previous":null,"results":[{"id":"ffhq","name":"FFHQ","full_name":"Flickr-Faces-HQ","url":"https://github.com/NVlabs/ffhq-dataset"},{"id":"lsun","name":"LSUN","full_name":"Large-scale
        Scene UNderstanding Challenge","url":"https://www.yf.io/p/lsun"}]}'
  recorded_at: Sun, 13 Nov 2022 15:39:21 GMT
recorded_with: VCR 6.1.0
